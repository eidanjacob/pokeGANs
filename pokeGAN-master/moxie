{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"moxie","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"FnO4xFFF4RsG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"8a13911b-17ba-4706-872c-b2b4ece49dce","executionInfo":{"status":"error","timestamp":1555782799626,"user_tz":240,"elapsed":369,"user":{"displayName":"Eidan Jacob","photoUrl":"https://lh4.googleusercontent.com/-W5VFD_lGdCY/AAAAAAAAAAI/AAAAAAAABlY/xLgktO8s5u4/s64/photo.jpg","userId":"10779154242604804842"}}},"cell_type":"code","source":["import os\n","import cv2\n","\n","src = \"./data\" #pokeRGB_black\n","dst = \"./resizedData\" # resized\n","if not os.path.exists(dst):\n","    os.mkdir(dst)\n","\n","for each in os.listdir(src):\n","    img = cv2.imread(os.path.join(src,each))\n","    img = cv2.resize(img,(256,256))\n","    cv2.imwrite(os.path.join(dst,each), img)\n","    "],"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e900b689b144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data'"]}]},{"metadata":{"id":"JCLcfdnP38oX","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import division\n","import math\n","import json\n","import random\n","import pprint\n","import scipy.misc\n","import numpy as np\n","from time import gmtime, strftime\n","from six.moves import xrange\n","\n","import tensorflow as tf\n","import tensorflow.contrib.slim as slim\n","\n","pp = pprint.PrettyPrinter()\n","\n","get_stddev = lambda x, k_h, k_w: 1/math.sqrt(k_w*k_h*x.get_shape()[-1])\n","\n","def show_all_variables():\n","  model_vars = tf.trainable_variables()\n","  slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n","\n","def get_image(image_path, input_height, input_width,\n","              resize_height=64, resize_width=64,\n","              crop=True, grayscale=False):\n","  image = imread(image_path, grayscale)\n","  return transform(image, input_height, input_width,\n","                   resize_height, resize_width, crop)\n","\n","def save_images(images, size, image_path):\n","  return imsave(inverse_transform(images), size, image_path)\n","\n","def imread(path, grayscale = False):\n","  if (grayscale):\n","    return scipy.misc.imread(path, flatten = True).astype(np.float)\n","  else:\n","    return scipy.misc.imread(path).astype(np.float)\n","\n","def merge_images(images, size):\n","  return inverse_transform(images)\n","\n","def merge(images, size):\n","  h, w = images.shape[1], images.shape[2]\n","  if (images.shape[3] in (3,4)):\n","    c = images.shape[3]\n","    img = np.zeros((h * size[0], w * size[1], c))\n","    for idx, image in enumerate(images):\n","      i = idx % size[1]\n","      j = idx // size[1]\n","      img[j * h:j * h + h, i * w:i * w + w, :] = image\n","    return img\n","  elif images.shape[3]==1:\n","    img = np.zeros((h * size[0], w * size[1]))\n","    for idx, image in enumerate(images):\n","      i = idx % size[1]\n","      j = idx // size[1]\n","      img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n","    return img\n","  else:\n","    raise ValueError('in merge(images,size) images parameter '\n","                     'must have dimensions: HxW or HxWx3 or HxWx4')\n","\n","def imsave(images, size, path):\n","  image = np.squeeze(merge(images, size))\n","  return scipy.misc.imsave(path, image)\n","\n","def center_crop(x, crop_h, crop_w,\n","                resize_h=64, resize_w=64):\n","  if crop_w is None:\n","    crop_w = crop_h\n","  h, w = x.shape[:2]\n","  j = int(round((h - crop_h)/2.))\n","  i = int(round((w - crop_w)/2.))\n","  return scipy.misc.imresize(\n","      x[j:j+crop_h, i:i+crop_w], [resize_h, resize_w])\n","\n","def transform(image, input_height, input_width, \n","              resize_height=64, resize_width=64, crop=True):\n","  if crop:\n","    cropped_image = center_crop(\n","      image, input_height, input_width, \n","      resize_height, resize_width)\n","  else:\n","    cropped_image = scipy.misc.imresize(image, [resize_height, resize_width])\n","  return np.array(cropped_image)/127.5 - 1.\n","\n","def inverse_transform(images):\n","  return (images+1.)/2.\n","\n","def to_json(output_path, *layers):\n","  with open(output_path, \"w\") as layer_f:\n","    lines = \"\"\n","    for w, b, bn in layers:\n","      layer_idx = w.name.split('/')[0].split('h')[1]\n","\n","      B = b.eval()\n","\n","      if \"lin/\" in w.name:\n","        W = w.eval()\n","        depth = W.shape[1]\n","      else:\n","        W = np.rollaxis(w.eval(), 2, 0)\n","        depth = W.shape[0]\n","\n","      biases = {\"sy\": 1, \"sx\": 1, \"depth\": depth, \"w\": ['%.2f' % elem for elem in list(B)]}\n","      if bn != None:\n","        gamma = bn.gamma.eval()\n","        beta = bn.beta.eval()\n","\n","        gamma = {\"sy\": 1, \"sx\": 1, \"depth\": depth, \"w\": ['%.2f' % elem for elem in list(gamma)]}\n","        beta = {\"sy\": 1, \"sx\": 1, \"depth\": depth, \"w\": ['%.2f' % elem for elem in list(beta)]}\n","      else:\n","        gamma = {\"sy\": 1, \"sx\": 1, \"depth\": 0, \"w\": []}\n","        beta = {\"sy\": 1, \"sx\": 1, \"depth\": 0, \"w\": []}\n","\n","      if \"lin/\" in w.name:\n","        fs = []\n","        for w in W.T:\n","          fs.append({\"sy\": 1, \"sx\": 1, \"depth\": W.shape[0], \"w\": ['%.2f' % elem for elem in list(w)]})\n","\n","        lines += \"\"\"\n","          var layer_%s = {\n","            \"layer_type\": \"fc\", \n","            \"sy\": 1, \"sx\": 1, \n","            \"out_sx\": 1, \"out_sy\": 1,\n","            \"stride\": 1, \"pad\": 0,\n","            \"out_depth\": %s, \"in_depth\": %s,\n","            \"biases\": %s,\n","            \"gamma\": %s,\n","            \"beta\": %s,\n","            \"filters\": %s\n","          };\"\"\" % (layer_idx.split('_')[0], W.shape[1], W.shape[0], biases, gamma, beta, fs)\n","      else:\n","        fs = []\n","        for w_ in W:\n","          fs.append({\"sy\": 5, \"sx\": 5, \"depth\": W.shape[3], \"w\": ['%.2f' % elem for elem in list(w_.flatten())]})\n","\n","        lines += \"\"\"\n","          var layer_%s = {\n","            \"layer_type\": \"deconv\", \n","            \"sy\": 5, \"sx\": 5,\n","            \"out_sx\": %s, \"out_sy\": %s,\n","            \"stride\": 2, \"pad\": 1,\n","            \"out_depth\": %s, \"in_depth\": %s,\n","            \"biases\": %s,\n","            \"gamma\": %s,\n","            \"beta\": %s,\n","            \"filters\": %s\n","          };\"\"\" % (layer_idx, 2**(int(layer_idx)+2), 2**(int(layer_idx)+2),\n","               W.shape[0], W.shape[3], biases, gamma, beta, fs)\n","    layer_f.write(\" \".join(lines.replace(\"'\",\"\").split()))\n","\n","def make_gif(images, fname, duration=2, true_image=False):\n","  import moviepy.editor as mpy\n","\n","  def make_frame(t):\n","    try:\n","      x = images[int(len(images)/duration*t)]\n","    except:\n","      x = images[-1]\n","\n","    if true_image:\n","      return x.astype(np.uint8)\n","    else:\n","      return ((x+1)/2*255).astype(np.uint8)\n","\n","  clip = mpy.VideoClip(make_frame, duration=duration)\n","  clip.write_gif(fname, fps = len(images) / duration)\n","\n","def visualize(sess, dcgan, config, option):\n","  image_frame_dim = int(math.ceil(config.batch_size**.5))\n","  if option == 0:\n","    z_sample = np.random.uniform(-0.5, 0.5, size=(config.batch_size, dcgan.z_dim))\n","    samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample})\n","    save_images(samples, [image_frame_dim, image_frame_dim], './samples/test_%s.png' % strftime(\"%Y%m%d%H%M%S\", gmtime()))\n","  elif option == 1:\n","    values = np.arange(0, 1, 1./config.batch_size)\n","    for idx in xrange(100):\n","      print(\" [*] %d\" % idx)\n","      z_sample = np.zeros([config.batch_size, dcgan.z_dim])\n","      for kdx, z in enumerate(z_sample):\n","        z[idx] = values[kdx]\n","\n","      if config.dataset == \"mnist\":\n","        y = np.random.choice(10, config.batch_size)\n","        y_one_hot = np.zeros((config.batch_size, 10))\n","        y_one_hot[np.arange(config.batch_size), y] = 1\n","\n","        samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample, dcgan.y: y_one_hot})\n","      else:\n","        samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample})\n","\n","      save_images(samples, [image_frame_dim, image_frame_dim], './samples/test_arange_%s.png' % (idx))\n","  elif option == 2:\n","    values = np.arange(0, 1, 1./config.batch_size)\n","    for idx in [random.randint(0, 99) for _ in xrange(100)]:\n","      print(\" [*] %d\" % idx)\n","      z = np.random.uniform(-0.2, 0.2, size=(dcgan.z_dim))\n","      z_sample = np.tile(z, (config.batch_size, 1))\n","      #z_sample = np.zeros([config.batch_size, dcgan.z_dim])\n","      for kdx, z in enumerate(z_sample):\n","        z[idx] = values[kdx]\n","\n","      if config.dataset == \"mnist\":\n","        y = np.random.choice(10, config.batch_size)\n","        y_one_hot = np.zeros((config.batch_size, 10))\n","        y_one_hot[np.arange(config.batch_size), y] = 1\n","\n","        samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample, dcgan.y: y_one_hot})\n","      else:\n","        samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample})\n","\n","      try:\n","        make_gif(samples, './samples/test_gif_%s.gif' % (idx))\n","      except:\n","        save_images(samples, [image_frame_dim, image_frame_dim], './samples/test_%s.png' % strftime(\"%Y%m%d%H%M%S\", gmtime()))\n","  elif option == 3:\n","    values = np.arange(0, 1, 1./config.batch_size)\n","    for idx in xrange(100):\n","      print(\" [*] %d\" % idx)\n","      z_sample = np.zeros([config.batch_size, dcgan.z_dim])\n","      for kdx, z in enumerate(z_sample):\n","        z[idx] = values[kdx]\n","\n","      samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample})\n","      make_gif(samples, './samples/test_gif_%s.gif' % (idx))\n","  elif option == 4:\n","    image_set = []\n","    values = np.arange(0, 1, 1./config.batch_size)\n","\n","    for idx in xrange(100):\n","      print(\" [*] %d\" % idx)\n","      z_sample = np.zeros([config.batch_size, dcgan.z_dim])\n","      for kdx, z in enumerate(z_sample): z[idx] = values[kdx]\n","\n","      image_set.append(sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample}))\n","      make_gif(image_set[-1], './samples/test_gif_%s.gif' % (idx))\n","\n","    new_image_set = [merge(np.array([images[idx] for images in image_set]), [10, 10]) \\\n","        for idx in range(64) + range(63, -1, -1)]\n","    make_gif(new_image_set, './samples/test_gif_merged.gif', duration=8)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NOc22Gp93Gg3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":643},"outputId":"cb87720e-325f-4e68-a87f-c15764e72b1d","executionInfo":{"status":"error","timestamp":1555782922636,"user_tz":240,"elapsed":4880,"user":{"displayName":"Eidan Jacob","photoUrl":"https://lh4.googleusercontent.com/-W5VFD_lGdCY/AAAAAAAAAAI/AAAAAAAABlY/xLgktO8s5u4/s64/photo.jpg","userId":"10779154242604804842"}}},"cell_type":"code","source":["\n","# -*- coding: utf-8 -*-\n","\n","# generate new kinds of pokemons\n","\n","import os\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","import random\n","import scipy.misc\n","\n","slim = tf.contrib.slim\n","\n","HEIGHT, WIDTH, CHANNEL = 128, 128, 3\n","BATCH_SIZE = 64\n","EPOCH = 5000\n","os.environ['CUDA_VISIBLE_DEVICES'] = '15'\n","version = 'newPokemon'\n","newPoke_path = './' + version\n","\n","def lrelu(x, n, leak=0.2): \n","    return tf.maximum(x, leak * x, name=n) \n"," \n","def process_data():   \n","    current_dir = os.getcwd()\n","    # parent = os.path.dirname(current_dir)\n","    pokemon_dir = os.path.join(current_dir, 'data')\n","    images = []\n","    for each in os.listdir(pokemon_dir):\n","        images.append(os.path.join(pokemon_dir,each))\n","    # print images    \n","    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n","    \n","    images_queue = tf.train.slice_input_producer(\n","                                        [all_images])\n","                                        \n","    content = tf.read_file(images_queue[0])\n","    image = tf.image.decode_jpeg(content, channels = CHANNEL)\n","    # sess1 = tf.Session()\n","    # print sess1.run(image)\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_brightness(image, max_delta = 0.1)\n","    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n","    # noise = tf.Variable(tf.truncated_normal(shape = [HEIGHT,WIDTH,CHANNEL], dtype = tf.float32, stddev = 1e-3, name = 'noise')) \n","    # print image.get_shape()\n","    size = [HEIGHT, WIDTH]\n","    image = tf.image.resize_images(image, size)\n","    image.set_shape([HEIGHT,WIDTH,CHANNEL])\n","    # image = image + noise\n","    # image = tf.transpose(image, perm=[2, 0, 1])\n","    # print image.get_shape()\n","    \n","    image = tf.cast(image, tf.float32)\n","    image = image / 255.0\n","    \n","    iamges_batch = tf.train.shuffle_batch(\n","                                    [image], batch_size = BATCH_SIZE,\n","                                    num_threads = 4, capacity = 200 + 3* BATCH_SIZE,\n","                                    min_after_dequeue = 200)\n","    num_images = len(images)\n","\n","    return iamges_batch, num_images\n","\n","def generator(input, random_dim, is_train, reuse=False):\n","    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 32 # channel num\n","    s4 = 4\n","    output_dim = CHANNEL  # RGB image\n","    with tf.variable_scope('gen') as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","        w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n","                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n","                             initializer=tf.constant_initializer(0.0))\n","        flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n","        # 4*4*512\n","        conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n","        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n","        act1 = tf.nn.relu(bn1, name='act1')\n","        # 8*8*256\n","        conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv2')\n","        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n","        act2 = tf.nn.relu(bn2, name='act2')\n","        # 16*16*128\n","        conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv3')\n","        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n","        act3 = tf.nn.relu(bn3, name='act3')\n","        # 32*32*64\n","        conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv4')\n","        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n","        act4 = tf.nn.relu(bn4, name='act4')\n","        # 64*64*32\n","        conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv5')\n","        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n","        act5 = tf.nn.relu(bn5, name='act5')\n","        \n","        #128*128*3\n","        conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv6')\n","        # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n","        act6 = tf.nn.tanh(conv6, name='act6')\n","        return act6\n","\n","\n","def discriminator(input, is_train, reuse=False):\n","    c2, c4, c8, c16 = 64, 128, 256, 512  # channel num: 64, 128, 256, 512\n","    with tf.variable_scope('dis') as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","        # 64*64*64\n","        conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv1')\n","        # bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n","        act1 = lrelu(conv1, n='act1')\n","        # 32*32*128\n","        conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv2')\n","        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n","        act2 = lrelu(bn2, n='act2')\n","        # 16*16*256\n","        conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv3')\n","        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n","        act3 = lrelu(bn3, n='act3')\n","        # 8*8*512\n","        conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv4')\n","        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n","        act4 = lrelu(bn4, n='act4')\n","        # # 8*8*256\n","        # conv5 = tf.layers.conv2d(act4, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 # kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 # name='conv5')\n","        # bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n","        # act5 = lrelu(bn5, n='act5')\n","        \n","        # start from act4\n","        dim = int(np.prod(act4.get_shape()[1:]))\n","        fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n","        # w1 = tf.get_variable('w1', shape=[fc1.shape[-1], 512], dtype=tf.float32,\n","                             # initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        # b1 = tf.get_variable('b1', shape=[512], dtype=tf.float32,\n","                             # initializer=tf.constant_initializer(0.0))\n","        # bnf = tf.contrib.layers.batch_norm(tf.matmul(fc1,w1), is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bnf')\n","        # act_fc1 = lrelu(tf.nn.bias_add(bnf, b1),n = 'actf')\n","        \n","        w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n","                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n","                             initializer=tf.constant_initializer(0.0))\n","\n","        # wgan just get rid of the sigmoid\n","        logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n","        # dcgan\n","        acted_out = tf.nn.sigmoid(logits)\n","        return logits #, acted_out\n","\n","\n","def train():\n","    random_dim = 100\n","    print(os.environ['CUDA_VISIBLE_DEVICES'])\n","    \n","    with tf.variable_scope('input'):\n","        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n","        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n","        is_train = tf.placeholder(tf.bool, name='is_train')\n","    \n","    # wgan\n","    fake_image = generator(random_input, random_dim, is_train)\n","    real_result = discriminator(real_image, is_train)\n","    fake_result = discriminator(fake_image, is_train, reuse=True)\n","    \n","    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  # This optimizes the discriminator.\n","    g_loss = -tf.reduce_mean(fake_result)  # This optimizes the generator.\n","    \n","    # # dcgan loss\n","    # fake_image = generator(random_input, random_dim, is_train)\n","    # # sample_fake = generator(random_input, random_dim, is_train, reuse = True)\n","    # real_logits, real_result = discriminator(real_image, is_train)\n","    # fake_logits, fake_result = discriminator(fake_image, is_train, reuse=True)\n","    \n","    # d_loss1 = tf.reduce_mean(\n","            # tf.nn.sigmoid_cross_entropy_with_logits(\n","            # logits = real_logits, labels = tf.ones_like(real_logits)))\n","    # d_loss2 = tf.reduce_mean(\n","            # tf.nn.sigmoid_cross_entropy_with_logits(\n","            # logits = fake_logits, labels = tf.zeros_like(fake_logits)))\n","    \n","    # d_loss = d_loss1 + d_loss2\n","    \n","    # g_loss = tf.reduce_mean(\n","            # tf.nn.sigmoid_cross_entropy_with_logits(\n","            # logits = fake_logits, labels = tf.ones_like(fake_logits)))\n","            \n","\n","    t_vars = tf.trainable_variables()\n","    d_vars = [var for var in t_vars if 'dis' in var.name]\n","    g_vars = [var for var in t_vars if 'gen' in var.name]\n","    # test\n","    # print(d_vars)\n","    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n","    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n","    # clip discriminator weights\n","    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n","\n","    \n","    batch_size = BATCH_SIZE\n","    image_batch, samples_num = process_data()\n","    \n","    batch_num = int(samples_num / batch_size)\n","    total_batch = 0\n","    sess = tf.Session()\n","    saver = tf.train.Saver()\n","    sess.run(tf.global_variables_initializer())\n","    sess.run(tf.local_variables_initializer())\n","    # continue training\n","    ckpt = tf.train.latest_checkpoint('./model/' + version)\n","    saver.restore(sess, ckpt)\n","    coord = tf.train.Coordinator()\n","    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n","\n","    print('total training sample num:%d' % samples_num)\n","    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n","    print('start training...')\n","    for i in range(EPOCH):\n","        for j in range(batch_num):\n","            d_iters = 5\n","            g_iters = 1\n","\n","            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n","            for k in range(d_iters):\n","                train_image = sess.run(image_batch)\n","                #wgan clip weights\n","                sess.run(d_clip)\n","                \n","                # Update the discriminator\n","                _, dLoss = sess.run([trainer_d, d_loss],\n","                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n","\n","            # Update the generator\n","            for k in range(g_iters):\n","                # train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n","                _, gLoss = sess.run([trainer_g, g_loss],\n","                                    feed_dict={random_input: train_noise, is_train: True})\n","\n","            # print 'train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss)\n","            \n","        # save check point every 500 epoch\n","        if i%500 == 0:\n","            if not os.path.exists('./model/' + version):\n","                os.makedirs('./model/' + version)\n","            saver.save(sess, './model/' +version + '/' + str(i))  \n","        if i%50 == 0:\n","            # save images\n","            if not os.path.exists(newPoke_path):\n","                os.makedirs(newPoke_path)\n","            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n","            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n","            # imgtest = imgtest * 255.0\n","            # imgtest.astype(np.uint8)\n","            save_images(imgtest, [8,8] ,newPoke_path + '/epoch' + str(i) + '.jpg')\n","            \n","            print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n","    coord.request_stop()\n","    coord.join(threads)\n","\n","\n","# def test():\n","    # random_dim = 100\n","    # with tf.variable_scope('input'):\n","        # real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n","        # random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n","        # is_train = tf.placeholder(tf.bool, name='is_train')\n","    \n","    # # wgan\n","    # fake_image = generator(random_input, random_dim, is_train)\n","    # real_result = discriminator(real_image, is_train)\n","    # fake_result = discriminator(fake_image, is_train, reuse=True)\n","    # sess = tf.InteractiveSession()\n","    # sess.run(tf.global_variables_initializer())\n","    # variables_to_restore = slim.get_variables_to_restore(include=['gen'])\n","    # print(variables_to_restore)\n","    # saver = tf.train.Saver(variables_to_restore)\n","    # ckpt = tf.train.latest_checkpoint('./model/' + version)\n","    # saver.restore(sess, ckpt)\n","\n","\n","if __name__ == \"__main__\":\n","    train()\n","    # test()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["15\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From <ipython-input-2-abd21db8e449>:80: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.conv2d_transpose instead.\n","WARNING:tensorflow:From <ipython-input-2-abd21db8e449>:119: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.conv2d instead.\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-abd21db8e449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;31m# test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-abd21db8e449>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_num\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-abd21db8e449>\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mpokemon_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpokemon_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpokemon_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# print images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data'"]}]}]}